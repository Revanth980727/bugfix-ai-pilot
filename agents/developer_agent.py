
import os
import time
import json
from typing import Dict, Any, List, Optional
import openai
from .utils.logger import Logger
from .utils.openai_client import OpenAIClient

class DeveloperAgent:
    """
    Agent responsible for generating code fixes based on PlannerAgent's task plan.
    Uses GPT-4 to generate code patches and handles multiple retry attempts.
    """
    
    def __init__(self, max_retries: int = 4):
        """
        Initialize the developer agent
        
        Args:
            max_retries: Maximum number of retry attempts for generating a successful patch
        """
        self.logger = Logger("developer_agent")
        self.max_retries = max_retries
        
        # Get repo path from environment
        self.repo_path = os.environ.get("REPO_PATH", "/mnt/codebase")
        
        # Initialize OpenAI client
        self.openai_client = OpenAIClient()
        
        # Get patch mode from environment (intelligent, line-by-line, direct)
        self.patch_mode = os.environ.get("PATCH_MODE", "line-by-line")
        self.logger.info(f"Using patch mode: {self.patch_mode}")
    
    def run(self, task_plan: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate code fixes based on the task plan
        
        Args:
            task_plan: The task plan generated by PlannerAgent including context with previous attempts
                       and QA failure information
            
        Returns:
            Dictionary with patch information:
            {
                "patch_content": "unified diff content",
                "patched_files": ["list", "of", "patched", "files"],
                "commit_message": "Description of changes",
                "attempt": 1,
                "success": true
            }
        """
        # Ensure we have a valid task_plan
        if not task_plan:
            self.logger.error("Invalid task plan: None or empty")
            return {
                "error": "Invalid task plan provided",
                "patch_content": "",
                "patched_files": [],
                "commit_message": "",
                "attempt": 1,
                "ticket_id": "unknown",
                "success": False
            }
            
        ticket_id = task_plan.get("ticket_id", "unknown")
        self.logger.start_task(f"Generating code fix for ticket {ticket_id}")
        
        # Extract context if available
        context = task_plan.get("context", {}) or {}  # Ensure context is a dict, not None
        attempt = context.get("attempt", 1)
        previous_attempts = context.get("previousAttempts", []) or []  # Ensure previous_attempts is a list, not None
            
        self.logger.info(f"Starting fix attempt {attempt}/{self.max_retries}")
        
        try:
            # Generate the fix using OpenAI
            patch_data = self.generate_fix(task_plan, attempt, previous_attempts)
            
            # Add metadata
            patch_data["attempt"] = attempt
            patch_data["ticket_id"] = ticket_id
            patch_data["patch_mode"] = self.patch_mode
            
            # Save patch to file
            patch_file_path = f"logs/patch_{ticket_id}_attempt_{attempt}.patch"
            os.makedirs("logs", exist_ok=True)
            with open(patch_file_path, "w") as f:
                f.write(patch_data.get("patch_content", "") or "")  # Handle None case
                
            self.logger.info(f"Patch saved to {patch_file_path}")
            
            # Set success status (actual verification happens in QA agent)
            patch_data["success"] = True
            
            self.logger.end_task(f"Code generation for ticket {ticket_id}", success=True)
            return patch_data
            
        except Exception as e:
            self.logger.error(f"Code generation failed: {str(e)}")
            self.logger.end_task(f"Code generation for ticket {ticket_id}", success=False)
            
            # Return error response
            return {
                "error": str(e),
                "patch_content": "",
                "patched_files": [],
                "commit_message": "",
                "attempt": attempt,
                "ticket_id": ticket_id,
                "success": False
            }
    
    # ... keep existing code (generate_fix method and related code)
    
    def _apply_patch(self, file_changes: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Apply patches to the repository files with precise line-by-line changes"""
        results = {
            "files_modified": [],
            "files_failed": [],
            "patches_applied": 0,
            "patched_code": {},  # Will store the actual patched code content
            "patch_mode": self.patch_mode
        }
        
        for change in file_changes:
            file_path = change.get("file_path", "unknown")
            diff = change.get("diff", "")
            
            # Skip if the file path is unknown or diff is empty
            if file_path == "unknown":
                self.logger.error(f"Skipping unknown file path")
                results["files_failed"].append({
                    "file": "unknown",
                    "reason": "File path could not be determined"
                })
                continue
                
            if not diff:
                self.logger.error(f"Skipping empty diff for file {file_path}")
                results["files_failed"].append({
                    "file": file_path,
                    "reason": "Empty diff content"
                })
                continue
            
            # Construct the full path
            full_path = os.path.join(self.repo_path, file_path.lstrip('/'))
            
            try:
                # Check if file exists
                if not os.path.exists(full_path):
                    # If it's a new file
                    dir_path = os.path.dirname(full_path)
                    if not os.path.exists(dir_path):
                        os.makedirs(dir_path)
                        
                    self.logger.info(f"Creating new file: {file_path}")
                    with open(full_path, 'w') as f:
                        # Remove diff markers before writing to a new file
                        clean_content = self._clean_diff_markers(diff)
                        f.write(clean_content)
                    
                    results["files_modified"].append(file_path)
                    results["patches_applied"] += 1
                    results["patched_code"][file_path] = clean_content
                    continue
                
                # For existing files, read the content
                with open(full_path, 'r', encoding='utf-8') as f:
                    original_content = f.read()
                
                # Apply patch based on selected mode
                if self.patch_mode == "line-by-line":
                    modified_content = self._apply_line_by_line_changes(original_content, diff)
                    self.logger.info(f"Applied line-by-line patching for {file_path}")
                elif self.patch_mode == "intelligent":
                    modified_content = self._apply_intelligent_patching(original_content, diff)
                    self.logger.info(f"Applied intelligent patching for {file_path}")
                else:
                    # Direct mode - use clean diff content if available, otherwise keep original
                    clean_content = self._clean_diff_markers(diff)
                    if clean_content and clean_content.strip():
                        modified_content = clean_content
                        self.logger.info(f"Applied direct content replacement for {file_path}")
                    else:
                        modified_content = original_content
                        self.logger.warning(f"Direct mode failed to extract content for {file_path}")
                
                # Skip if no changes were made
                if modified_content == original_content:
                    self.logger.warning(f"No changes were applied to {file_path}")
                    results["files_failed"].append({
                        "file": file_path,
                        "reason": "No changes could be applied"
                    })
                    continue
                    
                # Write the modified content back
                with open(full_path, 'w', encoding='utf-8') as f:
                    f.write(modified_content)
                
                # Store original and patched code
                results["patched_code"][file_path] = modified_content
                
                # Log success
                self.logger.info(f"Successfully patched file: {file_path}")
                results["files_modified"].append(file_path)
                results["patches_applied"] += 1
                
            except Exception as e:
                error_msg = f"Failed to patch {file_path}: {str(e)}"
                self.logger.error(error_msg)
                results["files_failed"].append({
                    "file": file_path,
                    "reason": str(e)
                })
        
        return results
        
    def _clean_diff_markers(self, content: str) -> str:
        """Remove diff markers and metadata from content when it's a complete file"""
        # If this doesn't look like a diff with markers, return as is
        if not any(line.startswith(('+', '-', '@@ ')) for line in content.splitlines()):
            return content
        
        # If it looks like a unified diff, extract only added lines (without the + marker)
        clean_lines = []
        for line in content.splitlines():
            # Skip diff metadata lines and removal lines
            if line.startswith('@@') or line.startswith('-'):
                continue
            # Include added lines (without the + marker)
            elif line.startswith('+'):
                clean_lines.append(line[1:])
            # Include context lines (without markers)
            elif not line.startswith(('-', '+')):
                clean_lines.append(line)
        
        return '\n'.join(clean_lines)

    def _apply_line_by_line_changes(self, original_content: str, diff: str) -> str:
        """
        Apply diff changes line by line to preserve most of the original file
        
        Args:
            original_content: The original file content
            diff: The diff content with - and + prefixes for line changes
            
        Returns:
            Modified content with changes applied
        """
        self.logger.info("Applying changes using line-by-line patching strategy")
        
        # Check if this is a proper diff format with +/- markers
        has_diff_markers = any(line.startswith('+') or line.startswith('-') 
                              for line in diff.splitlines())
        
        if not has_diff_markers:
            self.logger.warning("No diff markers found, returning original content")
            return original_content
            
        # Parse the diff to identify line changes
        original_lines = original_content.splitlines()
        result_lines = original_lines.copy()
        
        # Process diff lines to extract changes
        diff_lines = diff.splitlines()
        line_idx = 0  # Pointer to the current line in original content
        
        # Track specific added and removed lines precisely
        lines_to_remove = []  # List of (line_number, content) tuples
        lines_to_add = []     # List of (insert_position, content) tuples
        
        # First, identify the lines we need to remove
        for i, line in enumerate(diff_lines):
            if line.startswith('-'):
                line_content = line[1:]  # Remove the - marker
                # Try to find this line in the original content
                found = False
                
                # First, check if the next line in our current position matches
                if line_idx < len(original_lines) and line_content.strip() == original_lines[line_idx].strip():
                    lines_to_remove.append((line_idx, line_content))
                    found = True
                    
                # If not found at current position, search nearby lines
                if not found:
                    # Search in a window around our current position
                    window_size = 10
                    search_start = max(0, line_idx - window_size)
                    search_end = min(len(original_lines), line_idx + window_size)
                    
                    for j in range(search_start, search_end):
                        if original_lines[j].strip() == line_content.strip():
                            lines_to_remove.append((j, line_content))
                            found = True
                            # Update line_idx to continue from the line after the removed one
                            line_idx = j + 1
                            break
                            
                if not found:
                    self.logger.warning(f"Could not find line to remove: '{line_content[:40]}...'")
        
        # Now identify the lines we need to add
        for i, line in enumerate(diff_lines):
            if line.startswith('+'):
                line_content = line[1:]  # Remove the + marker
                
                # Try to find the best position for this addition
                insert_position = line_idx
                
                # If this addition follows a removal, insert at the position of the removal
                if i > 0 and diff_lines[i-1].startswith('-'):
                    removal_content = diff_lines[i-1][1:]
                    
                    # Find the corresponding removal in our tracked removals
                    for pos, content in lines_to_remove:
                        if content.strip() == removal_content.strip():
                            insert_position = pos
                            break
                
                lines_to_add.append((insert_position, line_content))
                
        # Sort lines to remove in reverse order to avoid index shifting
        lines_to_remove.sort(reverse=True)
        
        # Apply removals
        for line_num, _ in lines_to_remove:
            if 0 <= line_num < len(result_lines):
                del result_lines[line_num]
                
        # Sort additions by position
        lines_to_add.sort()
        
        # Apply additions with appropriate index adjustments
        offset = 0
        for orig_pos, content in lines_to_add:
            adjusted_pos = max(0, min(orig_pos + offset, len(result_lines)))
            result_lines.insert(adjusted_pos, content)
            offset += 1
        
        # If the diff didn't change anything, log a warning
        if result_lines == original_lines:
            self.logger.warning("Line-by-line patching did not change the file content")
            
            # Try a fallback approach - extract just the clean content from the diff
            clean_content = self._clean_diff_markers(diff)
            if clean_content and clean_content.strip() and clean_content != original_content:
                self.logger.info("Using fallback clean content extraction")
                return clean_content
        
        return '\n'.join(result_lines)
        
    def _apply_intelligent_patching(self, original_content: str, diff: str) -> str:
        """
        Apply intelligent patching that uses multiple strategies based on diff content
        
        Args:
            original_content: The original file content
            diff: The diff content
            
        Returns:
            Modified content with changes applied
        """
        self.logger.info("Applying changes using intelligent patching strategy")
        
        # First try standard line-by-line patching
        modified_content = self._apply_line_by_line_changes(original_content, diff)
        
        # If no changes were applied, check if we have a complete file replacement
        if modified_content == original_content:
            # Clean the diff and check if it looks like a complete file
            clean_content = self._clean_diff_markers(diff)
            
            # Heuristic: If the clean content has imports or class/function definitions, 
            # and is reasonably long, it might be a full file replacement
            looks_like_full_file = False
            if clean_content:
                lines = clean_content.splitlines()
                if len(lines) > 10:  # Reasonably sized file
                    code_markers = ['import ', 'class ', 'def ', 'function ', 'const ', 'let ', 'var ']
                    if any(marker in line for line in lines[:20] for marker in code_markers):
                        looks_like_full_file = True
                        
            if looks_like_full_file:
                self.logger.info("Intelligent patching: Detected full file replacement")
                return clean_content
                
            # If not a full file, try a chunk-based approach
            self.logger.info("Intelligent patching: Trying chunk-based approach")
            return self._apply_chunk_based_patching(original_content, diff)
            
        return modified_content
    
    def _apply_chunk_based_patching(self, original_content: str, diff: str) -> str:
        """
        Apply patching by identifying code chunks with logical boundaries
        
        Args:
            original_content: The original file content
            diff: The diff content
            
        Returns:
            Modified content with changes applied
        """
        # Identify logical chunks in the original content
        # (functions, classes, blocks, etc)
        original_lines = original_content.splitlines()
        chunks = []
        
        current_chunk = []
        current_indent = 0
        in_block = False
        
        # Simple chunk detection based on indentation and block markers
        for i, line in enumerate(original_lines):
            stripped_line = line.lstrip()
            
            # Skip empty lines
            if not stripped_line:
                current_chunk.append(line)
                continue
                
            # Calculate line indentation
            indent = len(line) - len(stripped_line)
            
            # Block start indicators
            if stripped_line.endswith('{') or stripped_line.endswith(':'):
                in_block = True
                current_indent = indent
                current_chunk.append(line)
            # End of block indicators
            elif in_block and indent <= current_indent and (stripped_line.startswith('}') or stripped_line.startswith(')')):
                current_chunk.append(line)
                # End of chunk
                if current_chunk:
                    chunks.append((i - len(current_chunk) + 1, '\n'.join(current_chunk)))
                current_chunk = []
                in_block = False
            # Block content or standalone line
            else:
                current_chunk.append(line)
                
                # If not in a block and line appears to be a complete statement, 
                # consider it as a chunk
                if not in_block and stripped_line.endswith(';'):
                    if current_chunk:
                        chunks.append((i - len(current_chunk) + 1, '\n'.join(current_chunk)))
                    current_chunk = []
        
        # Add any remaining chunk
        if current_chunk:
            chunks.append((len(original_lines) - len(current_chunk), '\n'.join(current_chunk)))
            
        # Find chunks in the diff that match or are similar to original chunks
        diff_lines = diff.splitlines()
        clean_diff_lines = []
        
        # Process only content lines in diff (ignore metadata)
        for line in diff_lines:
            if line.startswith('-'):
                continue
            elif line.startswith('+'):
                clean_diff_lines.append(line[1:])
            elif not line.startswith(('@', '---', '+++')):
                clean_diff_lines.append(line)
        
        clean_diff_content = '\n'.join(clean_diff_lines)
        
        # Try to find complete replacement chunks in the clean diff
        # This uses a similarity metric to identify chunks that correspond
        # to original chunks but have been modified
        modified_chunks = {}
        
        for i, (chunk_line, chunk_text) in enumerate(chunks):
            # Skip small chunks (likely not meaningful units)
            if len(chunk_text.splitlines()) < 3:
                continue
                
            # Look for similar chunks in the diff
            chunk_signatures = self._extract_chunk_signatures(chunk_text)
            
            for sig in chunk_signatures:
                if sig in clean_diff_content:
                    # Found a potential modified chunk in the diff
                    # Extract the surrounding context to get the full modified chunk
                    sig_pos = clean_diff_content.find(sig)
                    start_pos = max(0, sig_pos - 100)
                    end_pos = min(len(clean_diff_content), sig_pos + len(sig) + 300)
                    
                    modified_chunk = clean_diff_content[start_pos:end_pos]
                    
                    # Try to clean up the chunk to get proper boundaries
                    modified_chunk = self._clean_chunk_boundaries(modified_chunk)
                    
                    modified_chunks[chunk_line] = modified_chunk
                    break
        
        # Apply modified chunks to the original content
        if modified_chunks:
            result_lines = original_content.splitlines()
            
            # Apply changes from the highest line number to the lowest
            # to avoid index shifting
            for chunk_line in sorted(modified_chunks.keys(), reverse=True):
                modified_chunk = modified_chunks[chunk_line]
                
                # Find the end of the original chunk
                chunk_end = chunk_line
                for i, (next_chunk_line, _) in enumerate(chunks):
                    if next_chunk_line > chunk_line:
                        chunk_end = next_chunk_line - 1
                        break
                else:
                    chunk_end = len(result_lines)
                
                # Replace chunk
                chunk_length = chunk_end - chunk_line + 1
                result_lines[chunk_line:chunk_end+1] = modified_chunk.splitlines()
                
                self.logger.info(f"Replaced chunk at line {chunk_line}-{chunk_end}")
            
            return '\n'.join(result_lines)
            
        # If no chunks were modified, return the original content
        return original_content
    
    def _extract_chunk_signatures(self, chunk_text: str) -> List[str]:
        """Extract unique signatures that can identify a code chunk"""
        signatures = []
        
        # Get function/class names
        lines = chunk_text.splitlines()
        for line in lines:
            stripped = line.strip()
            
            # Look for function/method definitions
            if stripped.startswith(('def ', 'function ')):
                parts = stripped.split('(')[0].split()
                if len(parts) > 1:
                    signatures.append(parts[1])
                    
            # Look for class definitions
            elif stripped.startswith(('class ', 'interface ')):
                parts = stripped.split('(')[0].split()
                if len(parts) > 1:
                    class_name = parts[1].split(':')[0]
                    signatures.append(class_name)
        
        # If no specific identifiers found, use distinctive lines
        if not signatures:
            # Use the first few non-empty lines
            non_empty_lines = [line.strip() for line in lines if line.strip()]
            if non_empty_lines:
                signatures.append(non_empty_lines[0])
                if len(non_empty_lines) > 2:
                    signatures.append(non_empty_lines[2])
                    
        return signatures
    
    def _clean_chunk_boundaries(self, chunk: str) -> str:
        """Clean up chunk boundaries to ensure proper formatting"""
        lines = chunk.splitlines()
        
        # Find the first non-empty line
        start_idx = 0
        for i, line in enumerate(lines):
            if line.strip():
                start_idx = i
                break
                
        # Find the last non-empty line
        end_idx = len(lines) - 1
        for i in range(len(lines) - 1, -1, -1):
            if lines[i].strip():
                end_idx = i
                break
                
        # Extract the clean chunk
        clean_lines = lines[start_idx:end_idx+1]
        
        # Try to identify and fix indentation
        min_indent = float('inf')
        for line in clean_lines:
            if line.strip():
                indent = len(line) - len(line.lstrip())
                min_indent = min(min_indent, indent)
                
        if min_indent < float('inf'):
            # Adjust indentation
            clean_lines = [line[min_indent:] if line.strip() else line for line in clean_lines]
            
        return '\n'.join(clean_lines)
        
    # ... keep existing code (remaining methods)
